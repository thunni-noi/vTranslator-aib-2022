{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATTOEEoKmI2v",
        "outputId": "68222e5f-48f3-4972-9b94-f2d3d53ccd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12JRLeIsBrp-",
        "outputId": "3172a7c5-68a8-4342-866c-8538ee1c84a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for pytube (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip -q install git+https://github.com/thunni-noi/pytube.git\n",
        "%pip -q install pip install youtube_transcript_api\n",
        "%pip -q install moviepy\n",
        "%pip -q install pydub\n",
        "#modified version of pytube to support current youtube thingy\n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2hOiPsioPuq3"
      },
      "outputs": [],
      "source": [
        "import urllib.parse\n",
        "import re\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "def url_to_watch_id(url):\n",
        "  vid_list = []\n",
        "  pattern_watch = 'https://www.youtube.com/watch?'\n",
        "  pattern_short = 'https://youtu.be/'\n",
        "\n",
        "    #When using a normal URL\n",
        "  if re.match(pattern_watch,url):\n",
        "    yturl_qs = urllib.parse.urlparse(url).query\n",
        "    vid = urllib.parse.parse_qs(yturl_qs)['v'][0]\n",
        "    watch_id = vid\n",
        "\n",
        "    #For shortened URLs\n",
        "  elif re.match(pattern_short,url):\n",
        "    # \"https://youtu.be/\"The 11 characters following the video ID\n",
        "    vid = url[17:28]\n",
        "    watch_id = vid\n",
        "\n",
        "  else:\n",
        "    print('error:\\n URL is\\\"https://www.youtube.com/watch?\\\"Or')\n",
        "    print('  \\\"https://youtu.be/\\\"Please specify the URL that starts with.')\n",
        "    print('  - '+ str(i+1)+ 'Item:' + url)\n",
        "  return watch_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PiVyTSkqlcWc"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "import shutil\n",
        "\n",
        "def name_gen(path): #UNUSED\n",
        "  #if not name.endswith('.mp4') : filename = name+ '.mp4'\n",
        "  serial_num = 0\n",
        "  name = str(serial_num)\n",
        "  while os.path.exists(path+name+'.mp4') :\n",
        "    print(path+name+'.mp4 already exists!')\n",
        "    serial_num += 1\n",
        "    name = str(serial_num)\n",
        "    print(f'Trying {name}.mp4....')\n",
        "  return name + '.mp4', serial_num\n",
        "\n",
        "def download_video(url, path, vid_dw_number):\n",
        "  yt = YouTube(url)\n",
        "  filename = f'{vid_dw_number}.mp4'\n",
        "  if os.path.exists(os.path.join(path, filename)) : os.remove(os.path.join(path, filename))\n",
        "  serial_num = vid_dw_number\n",
        "  my_streams = yt.streams.filter(file_extension='mp4', progressive = True)\n",
        "  itag_list = []\n",
        "  res_list = []\n",
        "  for streams in my_streams :\n",
        "    itag_list.append(streams.itag)\n",
        "    res_list.append(int((streams.resolution).replace('p', '')))\n",
        "    #print(f\"Video itag : {streams.itag} Resolution : {streams.resolution} VCodec : {streams.codecs[0]}\")\n",
        "  best_res = min(res_list)\n",
        "  best_res_index = res_list.index(best_res)\n",
        "  print(f'Resolution : {best_res}, Itag : {itag_list[best_res_index]}')\n",
        "  video = yt.streams.get_by_itag(itag_list[best_res_index])\n",
        "  video.download(output_path = './' , filename = filename)\n",
        "  print(f'Downloaded {yt.title} as {filename}')\n",
        "  shutil.move(f'./{filename}', str(path))\n",
        "  output_path = os.path.join(path, filename)\n",
        "  return output_path, serial_num, url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "paHVHL6XNK9E"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from datetime import datetime, timedelta\n",
        "from moviepy.editor import *\n",
        "from pydub import AudioSegment\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "def video_to_mp3(input_path, output_path, serial):\n",
        "    output_path = os.path.join(output_path, str(serial))\n",
        "    if not os.path.exists(output_path):\n",
        "        print(f'{output_path} is not exists! Creating!!!')\n",
        "        os.makedirs(output_path)\n",
        "    video = VideoFileClip(input_path)\n",
        "    video.audio.write_audiofile(os.path.join(output_path, 'full.wav'))\n",
        "    return output_path\n",
        "  \n",
        "\n",
        "  \n",
        "def audio_breaker_timestamp(basepath, outputpath, timestamp_list):\n",
        "    audio_speech_list = []\n",
        "    baseAudio = AudioSegment.from_wav(basepath)\n",
        "    speech_order = 0\n",
        "    for startNend in timestamp_list:\n",
        "        cStart, cEnd = startNend.split('~')\n",
        "        newAudio = baseAudio[int(cStart):int(cEnd)]\n",
        "        newAudio.export(os.path.join(outputpath, f'{str(speech_order)}.mp3'), format = 'mp3')\n",
        "        audio_speech_list.append(os.path.join(outputpath, f'{str(speech_order)}.mp3'))\n",
        "        #print(f'Creating {speech_order}.wav!')\n",
        "        speech_order += 1\n",
        "    return audio_speech_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5vWMWRqdkeYH"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "def time_format(start, duration):\n",
        "  remove = bool(False)\n",
        "  start = str(start)\n",
        "  dur = str(duration)\n",
        "  while len(start.split('.')[1]) < 3 : start += '0'\n",
        "  while len(dur.split('.')[1]) < 3 : dur += '0'\n",
        "  start = int(start.replace('.',''))\n",
        "  dur = int(dur.replace('.',''))\n",
        "  if dur >= 1001 : remove = False\n",
        "  else : remove = True\n",
        "  startmilli = start\n",
        "  endmilli = dur + start\n",
        "  end = str(timedelta(milliseconds= (start + dur)))\n",
        "  start = str(timedelta(milliseconds=start))\n",
        "  start = (str(start)[2:])[:-3]\n",
        "  end = (str(end)[2:])[:-3]\n",
        "  return start, end, startmilli, endmilli, remove\n",
        "\n",
        "def transcript_file_gen(serial_num, transcript, path):\n",
        "  serial_num = str(serial_num)\n",
        "  txt_file = open(os.path.join(path, serial_num + '.txt'), 'w+')\n",
        "  output_path = (os.path.join(path, serial_num + 'txt'))\n",
        "  timestamp_list =  []\n",
        "  transcript_list = []\n",
        "  for seq in transcript:\n",
        "    txt = seq['text']\n",
        "    txt = txt.replace('\\u200b', '').replace('\\n', '').strip()\n",
        "    start = seq['start']\n",
        "    dur = seq['duration']\n",
        "    \n",
        "    if '：' in txt : txt = txt.split('：')[-1] \n",
        "    sStart, sEnd, tStart, tEnd, remove = time_format(start, dur)\n",
        "    if remove == True :\n",
        "      #print('skipped!')\n",
        "      continue\n",
        "    txt_file.write(f'{sStart} || {sEnd} || {txt} \\n')\n",
        "    timestamp_list.append(f'{str(tStart)}~{str(tEnd)}')\n",
        "    transcript_list.append(txt)\n",
        "    #print(txt)\n",
        "  return output_path,timestamp_list, transcript_list\n",
        "  #print(time_format(start).second)\n",
        "  #print(f'Text : {txt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WNiO1BSSluQ1"
      },
      "outputs": [],
      "source": [
        "#config!\n",
        "pl = Playlist('YOUTUBE_PLAYLIST_LINK') #change playlists urls here\n",
        "datasets_name = str('NAME') #change datasets name here\n",
        "# CAUTION : DO NOT SET THE NAME TO HAVE THE WORD 'CLEAN' OR SET DUPLICATED NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l5BDa4r5qN7o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pytube import Playlist\n",
        "pickle_folder_path = '/content/drive/MyDrive/livetranslator/pickle'\n",
        "datasets_path = f'/content/drive/MyDrive/livetranslator/{datasets_name}_datasets/'\n",
        "video_folder_path = os.path.join(datasets_path, 'video')\n",
        "audio_folder_path = os.path.join(datasets_path, 'audio')\n",
        "transcript_folder_path = os.path.join(datasets_path, 'transcript')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f_AFGvFfltf_"
      },
      "outputs": [],
      "source": [
        "#remove file\n",
        "import shutil\n",
        "if not os.path.exists(datasets_path) : os.makedirs(datasets_path)\n",
        "for f in os.listdir(datasets_path):\n",
        "    temppath = os.path.join(datasets_path, f)\n",
        "    try : \n",
        "        shutil.rmtree(temppath)\n",
        "    except OSError:\n",
        "        os.remove(temppath)\n",
        "temppath = 'NA'\n",
        "del temppath\n",
        "os.makedirs(video_folder_path)\n",
        "os.makedirs(audio_folder_path)\n",
        "os.makedirs(transcript_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCoMPTnQTRRM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "urls = list(pl.video_urls)\n",
        "dataframe = pd.DataFrame(columns = ['path', 'sentence'])\n",
        "error_unuse = 0\n",
        "if not datasets_name.endswith('_') : str(datasets_name) + str('_')\n",
        "vid_info = []\n",
        "for temp_index in tqdm_notebook(range(0,len(urls)), total = len(urls), desc = 'Downloading and extracing audio/transcript from playlists : '):\n",
        "  try :\n",
        "    transcript= YouTubeTranscriptApi.get_transcript(url_to_watch_id(urls[temp_index]), languages=['ja'])\n",
        "  except Exception as err :\n",
        "    print(f'Error, Something went wrong, Error')\n",
        "    line_noti_msg(f'Found error : skipping {err}')\n",
        "    error_unuse += 1\n",
        "    continue\n",
        "  index = temp_index - error_unuse\n",
        "  download_watch_id = url_to_watch_id(urls[index])\n",
        "  try :\n",
        "    download_path, download_number, download_url = download_video(str(urls[index]), video_folder_path, index)\n",
        "  except Exception as err :\n",
        "    print(f'Error, Something went wrong, Error')\n",
        "    line_noti_msg(f'Found error : skipping {err}')\n",
        "    error_unuse += 1\n",
        "    continue\n",
        "  \n",
        "  temp_dict = {'url' : download_url,'watch_id' : download_watch_id,'video_path' : download_path, 'serial_number' : download_number }\n",
        "  vid_info.append(temp_dict)\n",
        "  del temp_dict\n",
        "  \n",
        "  transcript_textpath, transcript_timestamp_list, transcript_sub_list = transcript_file_gen(index, transcript, transcript_folder_path)\n",
        "  vid_info[index]['transcript_path'] = transcript_textpath\n",
        "  vid_info[index]['timestamp'] = transcript_timestamp_list\n",
        "  vid_info[index]['transcript_list'] = transcript_sub_list\n",
        "  vid_info[index]['audio_path'] = video_to_mp3(vid_info[index]['video_path'],audio_folder_path , vid_info[index]['serial_number'])\n",
        "  vid_info[index]['speech_list'] = audio_breaker_timestamp(\n",
        "    os.path.join(vid_info[index]['audio_path'], 'full.wav'), \n",
        "    os.path.join(vid_info[index]['audio_path']), \n",
        "    vid_info[index]['timestamp'])\n",
        "  for i, speech in enumerate(vid_info[index]['speech_list']):\n",
        "    dataframe = dataframe.append({'path' : speech, 'sentence' : vid_info[index]['transcript_list'][i]},ignore_index = True)\n",
        "\n",
        "dataframe = dataframe.drop(dataframe[dataframe['sentence'] == ''].index) #drop if subtitle is empty\n",
        "dataframe.to_pickle(os.path.join(pickle_folder_path, f'{datasets_name}.pkl'))\n",
        "  #df_train.to_excel(os.path.join(datasets_path, f'{datasets_name}_test.xlsx'))\n",
        "print(f'Finished downloading datasets. Total : {len(dataframe)} audio were extracted!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovrH5BX8hLN9"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of youtube_datasets_subtitle.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
